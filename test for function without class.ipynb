{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import cx_Oracle\n",
    "from IPython.display import IFrame    #to display pdf file\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save this one \n",
    "def classify_32(dataframe, state, isPickle):\n",
    "    \n",
    "    '''\n",
    "    This function takes in dataframe, and classify the store type to either it is a LowPoint store or not.\n",
    "        LowPoint_Y = True: stores that can only sell 3.2% beer.\n",
    "        LowPoint_Y = False: stores that can sell any beer.\n",
    "    \n",
    "    Parameter:\n",
    "    ---------\n",
    "        state: takes a string. Indicates the state.\n",
    "        isPickle: takes a boolean. Indicates classification method. 'True' for pickle, 'False' for grid search\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "        the dataframe with prediction result under 'LowPoint_Y' column.\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    #define a function to get the subset of dataframe\n",
    "    def classification_subset_32(dataframe, state):\n",
    "\n",
    "        '''\n",
    "        This function subsets the dataframe to prepare classification.\n",
    "\n",
    "        parameter:\n",
    "        ---------\n",
    "            state: Takes a string. The name of state to subset dataframe. \n",
    "            \n",
    "        return:\n",
    "        -------\n",
    "            The subsetted dataframe.        \n",
    "        '''\n",
    "\n",
    "        #load the columns for subset from pickle:\n",
    "        subset_columns = pickle.load(open('classification_columns.p', 'rb'))\n",
    "\n",
    "        #subset the dataframe:\n",
    "        classification_df = pd.DataFrame(dataframe[subset_columns])\n",
    "\n",
    "        classification_df = classification_df[classification_df['RTL_STATE_DSC'] == str(state).upper()]\n",
    "\n",
    "        \n",
    "    \n",
    "    #define a function to run pickle for decision tree model. \n",
    "    def decision_tree_pickle_32(classification_df, state):\n",
    "\n",
    "        '''\n",
    "        This function takes the name of the state, and using the subsetted dataframe from function 'classification_subset' \n",
    "            to classify the stores using pickled decision tree model. \n",
    "\n",
    "        parameter:\n",
    "        ----------\n",
    "            classification_df: Takes a dataframe. The subsetted dataframe after excuting the function \"classification_subset\"\n",
    "            state: Takes a string. The name of the State\n",
    "\n",
    "        return:\n",
    "        -------\n",
    "            The dataframe with prediction result.        \n",
    "        '''\n",
    "        #call the binarize function to transform the columns into binary\n",
    "        columns = [c for c in classification_df.columns if c not in ['RTL_STORE_CD',\"LowPoint_Y\"]]\n",
    "        result_df = pd.concat([classification_df, pd.get_dummies(classification_df[columns] , prefix = ['B_'+c for c in columns])] , axis = 1)\n",
    "        \n",
    "        #load the model from pickle for that state\n",
    "        filename = str(state).title()+'_decision_tree_model.p'\n",
    "        decision_tree_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "        #prepare independent variables:\n",
    "        X_labels = [c for c in result_df.columns if c not in [classification_df.columns]]\n",
    "        X = result_df.loc[:,X_labels]\n",
    "\n",
    "        #dependent variable:\n",
    "        result_df['LowPoint_Y'] = decision_tree_model.predict(X) == 'LowPoint'\n",
    "        \n",
    "    #define a function to run pickle for business rule. \n",
    "    def business_rule_pickle_32(classification_df, state):\n",
    "        '''\n",
    "        This function takes the name of the state, and using the subsetted dataframe from function 'classification_subset' \n",
    "            to classify the stores using pickled business rule.\n",
    "\n",
    "        parameter:\n",
    "        ----------\n",
    "            state: Takes a string. The name of the State\n",
    "            classification_df: Takes a dataframe. The subsetted dataframe after excuting the function \"classification_subset\"\n",
    "\n",
    "        return:\n",
    "        -------\n",
    "            The dataframe with prediction result.        \n",
    "        '''    \n",
    "\n",
    "        #load the business rule from pickle for that State\n",
    "        filename = str(state).title()+'_business_rule.p'\n",
    "        rule_func = pickle.load(open('filename.p', 'rb'))\n",
    "\n",
    "        #make the prediction\n",
    "        result_df = classification_df\n",
    "        result_df['LowPoint_Y'] = rule_func(classification_df)\n",
    "    \n",
    "\n",
    "    def read_query_and_predict_32(self, classification_df, state):\n",
    "    \n",
    "        '''\n",
    "        This function queries from Oracle SQL for specific state and store type and save the data in a dataframe. Then, use decision\n",
    "            tree classifier to train the labeled data, and make prediction on whole dataset.\n",
    "\n",
    "        parameter:\n",
    "        ---------\n",
    "            classification_df: Takes a dataframe. The subsetted dataframe after excuting the function \"classification_subset\"\n",
    "            state: Takes a string. The state name\n",
    "\n",
    "        return:\n",
    "        -------\n",
    "            a dataframe with prediction result. \n",
    "        '''\n",
    "\n",
    "\n",
    "        #Access to Oracle DB\n",
    "        host = 'tncluster6.cbi.net'\n",
    "        port = 1521\n",
    "        s_name = 'EDW1TS_EX.cbi.net'\n",
    "        dsn_tns = cx_Oracle.makedsn(host, port, service_name = s_name)\n",
    "        db_ts = cx_Oracle.connect('USERNAME', 'PASSWORD', dsn_tns)\n",
    "        cursor = db_ts.cursor()\n",
    "\n",
    "        if str(state) == 'Kansas'.casefold():\n",
    "            state_code = str(162)\n",
    "        elif str(state) == 'Utah'.casefold():\n",
    "            state_code = str(239)\n",
    "        elif str(state) == 'Minnesota'.casefold():\n",
    "            state_code = str(177)\n",
    "        elif str(state) == 'Corolado'.casefold():\n",
    "            state_code = str(125)\n",
    "        elif str(state) == 'Oklahoma'.casefold():\n",
    "            state_code = str(201)\n",
    "\n",
    "        query = '''select /*+ parallel(6) */ a15.STORE_CD  RTL_STORE_CD, 'NonLowPoint' as \"BEERTYPE\"\n",
    "                    from EDW.BI_CRN_F_RETAIL_DEPL_MVW_VW a11\n",
    "                    join EDW.BI_CRN_D_ITEM_VW a12\n",
    "                       on  (a11.ITEM_ID = a12.ITEM_ID)\n",
    "                     join EDW.BI_CRN_D_REL_TIME_DETAIL_VW a13\n",
    "                       on  (a11.DATE_ID = a13.REL_DATE_ID)\n",
    "                     join EDW.BI_CRN_D_DISTRIBUTOR_VW a14\n",
    "                       on  (a11.DIST_ID = a14.DIST_ID)\n",
    "                     join EDW.BI_CRN_D_RETAILER_VW a15\n",
    "                       on  (a11.RETAILER_ID = a15.RETAILER_ID)\n",
    "                    where (a13.REL_TIME_CD in ('L3_TY')\n",
    "                     and a14.STATE_PROVINCE_COUNTRY_CD in (''' + \"'\" + state_code + \"')\" + ''' and a12.MASTER_SKU_CD not in ('80013450', '80013452', '80013455', '80013979', '80013456', '80013475', '80061325', '80013477', '80013982', '80013980', '80059842', '80058839', '80014020', '80014022', '80014023', '80014024', '80014025', '80013992', '80013991', '80013464', '80013466', '80013469', '80013471', '80013472', '80013473', '80013478', '80031998', '80013485', '80056926', '80058838', '80019746', '80031994', '80015966', '80014017', '80012704', '80014015', '80014009', '80014011', '80024732', '80013994', '80056172', '80014010'))\n",
    "                    group by a15.STORE_CD\n",
    "                    UNION \n",
    "                    select /*+ parallel(6) */ a15.STORE_CD  RTL_STORE_CD,\n",
    "                     'LowPoint' as \"BEERTYPE\"\n",
    "                    from EDW.BI_CRN_F_RETAIL_DEPL_MVW_VW a11\n",
    "                     join EDW.BI_CRN_D_ITEM_VW a12\n",
    "                       on  (a11.ITEM_ID = a12.ITEM_ID)\n",
    "                     join EDW.BI_CRN_D_REL_TIME_DETAIL_VW a13\n",
    "                       on  (a11.DATE_ID = a13.REL_DATE_ID)\n",
    "                     join EDW.BI_CRN_D_DISTRIBUTOR_VW a14\n",
    "                       on  (a11.DIST_ID = a14.DIST_ID)\n",
    "                     join EDW.BI_CRN_D_RETAILER_VW a15\n",
    "                       on  (a11.RETAILER_ID = a15.RETAILER_ID)\n",
    "                    where (a13.REL_TIME_CD in ('L3_TY')\n",
    "                     and a14.STATE_PROVINCE_COUNTRY_CD in (''' +\"'\" + state_code + \"')\" + ''' and a12.MASTER_SKU_CD not in ('80029020', '80060325', '80032234', '80032233', '80023100', '80031072', '80013435', '80013437', '80013439', '80057078', '80014016', '80013442', '80026873', '80056799', '80013444', '80014014', '80013447', '80013460', '80013457', '80013458', '80059543', '80013461', '80059542', '80059571', '80059572', '80059573', '80013982', '80013980', '80056922', '80014002', '80013968', '80029050', '80013515', '80013516', '80013517', '80013518', '80018933', '80056908', '80013520', '80014006', '80013993', '80013522', '80014026', '80013984', '80013978', '80013970', '80014012', '80014060', '80013986', '80013977', '80060330', '80060331', '80060328', '999', '80014008', '80013995', '80013972', '80056887', '80014001', '80031989', '80013985', '80013971', '80013983', '80014007', '80029021', '80015214', '80015215', '80014005', '80014004', '80013976', '80013990', '80013998', '80013989', '80013975', '80013997', '80027630', '80027631', '80027632', '80062390', '80062550', '80013996', '80014013', '80013988', '80013987', '80013974', '80013973', '80013999', '80014000', 'UNK', '80013981'))\n",
    "                    group by a15.STORE_CD '''\n",
    "\n",
    "        try:\n",
    "            cursor.execute(query)\n",
    "            names = [ x[0] for x in cursor.description]\n",
    "            rows = cursor.fetchall()\n",
    "            StoreType = pd.DataFrame( rows, columns=names)\n",
    "\n",
    "        finally:\n",
    "            if cursor is not None:\n",
    "                cursor.close()\n",
    "\n",
    "        #If the above code runs sucessfully, it will return a dataframe which columns: store number and store type(LowPoint or NonLowPoint)\n",
    "\n",
    "\n",
    "\n",
    "        #left join the store type data with subsetted dataframe\n",
    "        result_df = pd.merge(classification_df, StoreType, on=\"RTL_STORE_CD\", how=\"left\")  \n",
    "\n",
    "        #call the binarize function to transform the columns into binary\n",
    "        result_df = self.binarize([c for c in classification_df.columns if c not in ['RTL_STORE_CD',\"LowPoint_Y\"]])\n",
    "\n",
    "        #subset the training dataset\n",
    "        train_df = result_df.loc[result_df['BEERTYPE'] == 'LowPoint' or result_df['BEERTYPE'] == 'NonLowPoint']  \n",
    "\n",
    "        #fit the model using traning data\n",
    "        #independent variables:\n",
    "        X_labels = [c for c in train_df.columns if c not in [classification_df.columns]]\n",
    "        X_train = train_df.loc[:,X_labels]\n",
    "        #dependent variable:\n",
    "        Y_train = train_df.loc['BEERTYPE'] \n",
    "\n",
    "        #train the model, and find the best parameter\n",
    "        parameters = {'max_depth':range(1,21), 'min_samples_leaf':range(3,21,3), 'min_samples_split':range(3,21,3), 'random_state': [0]}\n",
    "        clf = tree.DecisionTreeClassifier()\n",
    "        clf = GridSearchCV(clf, parameters, n_jobs = -2)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        accuracy = clf.best_score_ \n",
    "        best_params = clf.best_params_\n",
    "        best_depth = best_params['max_depth']\n",
    "        best_leaf = best_params['min_samples_leaf']\n",
    "        best_split = best_params['min_samples_split']\n",
    "\n",
    "        #using the best parameter to train and fit the model\n",
    "        clf = tree.DecisionTreeClassifier(max_depth=best_depth, min_samples_leaf= best_leaf, min_samples_split = best_split, random_state=0)\n",
    "        clf = clf.fit(X_train,Y_train)\n",
    "\n",
    "        #Prepare for prediction dataset\n",
    "        X_pred = result_df.loc[:,X_labels]\n",
    "\n",
    "        #make prediction for whole dataset.\n",
    "        result_df['LowPoint_Y'] = clf.predict(X_pred) == 'LowPoint_Y'        \n",
    "\n",
    "        #delete the column 'BEERTYPE'\n",
    "        del result_df['BEERTYPE']    \n",
    "     \n",
    "    \n",
    "    \n",
    "    ###############################excute code########################\n",
    "    \n",
    "    #create a LowPoint_Y column for entire dataset. \n",
    "    dataframe['LowPoint_Y'] = ''\n",
    "    \n",
    "    #take a subset of the data classification_subset \n",
    "    classification_df = self.classification_subset(self.data)\n",
    "    \n",
    "    #if using Pickle\n",
    "    if isPickle:\n",
    "        \n",
    "        #Decision tree model for Kansas and Minnesota\n",
    "        #If the state is Kansas:\n",
    "        if state == 'Kansas'.casefold():\n",
    "            self.decision_tree_pickle(classification_df, 'Kansas')\n",
    "\n",
    "        #If the state is Minnesota:   \n",
    "        elif state == 'Minnesota'.casefold():\n",
    "            self.decision_tree_pickle(classification_df, 'Minnesota')\n",
    "      \n",
    "    \n",
    "        #Business rule for Utah, Oklahoma, and Colorado\n",
    "        #If the state is Utah:\n",
    "        elif state == 'Utah'.casefold():\n",
    "            self.business_rule_pickle(classification_df, 'Utah')\n",
    "            \n",
    "        #If the state is Oklahoma:   \n",
    "        elif state == 'Oklahoma'.casefold():\n",
    "            self.business_rule_pickle(classification_df, 'Oklahoma')\n",
    "\n",
    "\n",
    "        #If the state is Colorado:  \n",
    "        elif state == 'Colorado'.casefold():\n",
    "            self.business_rule_pickle(classification_df, 'Colorado')\n",
    "\n",
    "        #If enter other States:\n",
    "        else:\n",
    "            print('wrong state')\n",
    "            break\n",
    "    \n",
    "    #if using grid search\n",
    "    else:\n",
    "        \n",
    "        #If the state is Kansas:\n",
    "        if state == 'Kansas'.casefold():\n",
    "            #get the query result as dataframe and get the prediction result\n",
    "            self.read_query_and_predict(classification_df, 'Kansas')\n",
    "        \n",
    "        #If the state is Minnesota:    \n",
    "        elif state == 'Minnesota'.casefold():\n",
    "            #get the query result as dataframe and get the prediction result\n",
    "            self.read_query_and_predict(classification_df, 'Minnesota')\n",
    "\n",
    "        else:\n",
    "            print('wrong state')\n",
    "            break \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_query_and_predict_32(self, classification_df, state):\n",
    "    \n",
    "    #Access to Oracle DB\n",
    "    host = 'tncluster6.cbi.net'\n",
    "    port = 1521\n",
    "    s_name = 'EDW1TS_EX.cbi.net'\n",
    "    dsn_tns = cx_Oracle.makedsn(host, port, service_name = s_name)\n",
    "    db_ts = cx_Oracle.connect('USERNAME', 'PASSWORD', dsn_tns)\n",
    "    cursor = db_ts.cursor()\n",
    "\n",
    "    if str(state) == 'Kansas'.casefold():\n",
    "        state_code = str(162)\n",
    "    elif str(state) == 'Utah'.casefold():\n",
    "        state_code = str(239)\n",
    "    elif str(state) == 'Minnesota'.casefold():\n",
    "        state_code = str(177)\n",
    "    elif str(state) == 'Corolado'.casefold():\n",
    "        state_code = str(125)\n",
    "    elif str(state) == 'Oklahoma'.casefold():\n",
    "        state_code = str(201)\n",
    "\n",
    "    query = '''select /*+ parallel(6) */ a15.STORE_CD  RTL_STORE_CD, 'NonLowPoint' as \"BEERTYPE\"\n",
    "                    from EDW.BI_CRN_F_RETAIL_DEPL_MVW_VW a11\n",
    "                    join EDW.BI_CRN_D_ITEM_VW a12\n",
    "                       on  (a11.ITEM_ID = a12.ITEM_ID)\n",
    "                     join EDW.BI_CRN_D_REL_TIME_DETAIL_VW a13\n",
    "                       on  (a11.DATE_ID = a13.REL_DATE_ID)\n",
    "                     join EDW.BI_CRN_D_DISTRIBUTOR_VW a14\n",
    "                       on  (a11.DIST_ID = a14.DIST_ID)\n",
    "                     join EDW.BI_CRN_D_RETAILER_VW a15\n",
    "                       on  (a11.RETAILER_ID = a15.RETAILER_ID)\n",
    "                    where (a13.REL_TIME_CD in ('L3_TY')\n",
    "                     and a14.STATE_PROVINCE_COUNTRY_CD in (''' + \"'\" + state_code + \"')\" + ''' and a12.MASTER_SKU_CD not in ('80013450', '80013452', '80013455', '80013979', '80013456', '80013475', '80061325', '80013477', '80013982', '80013980', '80059842', '80058839', '80014020', '80014022', '80014023', '80014024', '80014025', '80013992', '80013991', '80013464', '80013466', '80013469', '80013471', '80013472', '80013473', '80013478', '80031998', '80013485', '80056926', '80058838', '80019746', '80031994', '80015966', '80014017', '80012704', '80014015', '80014009', '80014011', '80024732', '80013994', '80056172', '80014010'))\n",
    "                    group by a15.STORE_CD\n",
    "                    UNION \n",
    "                    select /*+ parallel(6) */ a15.STORE_CD  RTL_STORE_CD,\n",
    "                     'LowPoint' as \"BEERTYPE\"\n",
    "                    from EDW.BI_CRN_F_RETAIL_DEPL_MVW_VW a11\n",
    "                     join EDW.BI_CRN_D_ITEM_VW a12\n",
    "                       on  (a11.ITEM_ID = a12.ITEM_ID)\n",
    "                     join EDW.BI_CRN_D_REL_TIME_DETAIL_VW a13\n",
    "                       on  (a11.DATE_ID = a13.REL_DATE_ID)\n",
    "                     join EDW.BI_CRN_D_DISTRIBUTOR_VW a14\n",
    "                       on  (a11.DIST_ID = a14.DIST_ID)\n",
    "                     join EDW.BI_CRN_D_RETAILER_VW a15\n",
    "                       on  (a11.RETAILER_ID = a15.RETAILER_ID)\n",
    "                    where (a13.REL_TIME_CD in ('L3_TY')\n",
    "                     and a14.STATE_PROVINCE_COUNTRY_CD in (''' +\"'\" + state_code + \"')\" + ''' and a12.MASTER_SKU_CD not in ('80029020', '80060325', '80032234', '80032233', '80023100', '80031072', '80013435', '80013437', '80013439', '80057078', '80014016', '80013442', '80026873', '80056799', '80013444', '80014014', '80013447', '80013460', '80013457', '80013458', '80059543', '80013461', '80059542', '80059571', '80059572', '80059573', '80013982', '80013980', '80056922', '80014002', '80013968', '80029050', '80013515', '80013516', '80013517', '80013518', '80018933', '80056908', '80013520', '80014006', '80013993', '80013522', '80014026', '80013984', '80013978', '80013970', '80014012', '80014060', '80013986', '80013977', '80060330', '80060331', '80060328', '999', '80014008', '80013995', '80013972', '80056887', '80014001', '80031989', '80013985', '80013971', '80013983', '80014007', '80029021', '80015214', '80015215', '80014005', '80014004', '80013976', '80013990', '80013998', '80013989', '80013975', '80013997', '80027630', '80027631', '80027632', '80062390', '80062550', '80013996', '80014013', '80013988', '80013987', '80013974', '80013973', '80013999', '80014000', 'UNK', '80013981'))\n",
    "                    group by a15.STORE_CD '''\n",
    "\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        names = [ x[0] for x in cursor.description]\n",
    "        rows = cursor.fetchall()\n",
    "        StoreType = pd.DataFrame( rows, columns=names)\n",
    "\n",
    "    finally:\n",
    "        if cursor is not None:\n",
    "            cursor.close()\n",
    "\n",
    "    #If the above code runs sucessfully, it will return a dataframe which columns: store number and store type(LowPoint or NonLowPoint)\n",
    "\n",
    "\n",
    "    #train decision tree:\n",
    "    \n",
    "    #left join the store type data with subsetted dataframe\n",
    "    result_df = pd.merge(classification_df, StoreType, on=\"RTL_STORE_CD\", how=\"left\")  \n",
    "\n",
    "    #call the binarize function to transform the columns into binary\n",
    "    columns = [c for c in classification_df.columns if c not in ['RTL_STORE_CD','LowPoint_Y', 'RTL_STATE_DSC']]\n",
    "    result_df = pd.concat([classification_df, pd.get_dummies(classification_df[columns] , prefix = ['B_'+c for c in columns])] , axis = 1)\n",
    "        \n",
    "    #subset the training dataset\n",
    "    train_df = result_df.loc[result_df['BEERTYPE'] == 'LowPoint' or result_df['BEERTYPE'] == 'NonLowPoint']  \n",
    "\n",
    "    #fit the model using traning data\n",
    "    \n",
    "    #independent variables:\n",
    "    X_labels = [c for c in train_df.columns if c not in list(classification_df.columns)]\n",
    "    X_train = train_df.loc[:,X_labels]\n",
    "    #dependent variable:\n",
    "    Y_train = train_df.loc['BEERTYPE'] \n",
    "    \n",
    "    #train the model, and fit.\n",
    "    decision_tree_train_and_fit(X_train, Y_train, state)\n",
    "    \n",
    "    #load the best model:\n",
    "    filename = str(state).title()+'_decision_tree_model.p'\n",
    "    clf = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    #Prepare for prediction dataset\n",
    "    X_pred = result_df.loc[:,X_labels]\n",
    "\n",
    "    #make prediction for whole dataset.\n",
    "    result_df['LowPoint_Y'] = clf.predict(X_pred) == 'LowPoint_Y'        \n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# successful code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function to get the subset of dataframe\n",
    "def classification_subset_32(dataframe, state):\n",
    "\n",
    "\n",
    "    #load the columns for subset from pickle:\n",
    "    subset_columns = pickle.load(open('classification_columns.p', 'rb'))\n",
    "    \n",
    "    #subset the dataframe:\n",
    "    classification_df = pd.DataFrame(dataframe[subset_columns])\n",
    "\n",
    "    classification_df = classification_df[classification_df['RTL_STATE_DSC'] == str(state).upper()]\n",
    "    return classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function for business_rule_pickle\n",
    "def business_rule_pickle_32(classification_df, state):  \n",
    "\n",
    "    #load the business rule from pickle for that State\n",
    "    filename = str(state).title()+'_business_rule.p'\n",
    "    rule_func = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    #make the prediction\n",
    "    result_df = classification_df\n",
    "    result_df['LowPoint_Y'] = rule_func(result_df)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#business rule pickle Utah\n",
    "def Rules_Utah(dataframe):\n",
    "    result_list = []\n",
    "    for row in range(len(dataframe)):\n",
    "        if dataframe.loc[row,'RTL_CHANNEL_DSC'] == 'LIQUOR' or 'MILITARY' in dataframe.loc[row,'RTL_CHANNEL_DSC']:\n",
    "            result_list.append(False)\n",
    "        else:\n",
    "            result_list.append(True)  \n",
    "    return result_list\n",
    "\n",
    "#save the Utah business rule into pickle\n",
    "pickle.dump(Rules_Utah, open('Utah_business_rule.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#business rule pickle Oklahoma\n",
    "def Rules_Oklahoma(dataframe):\n",
    "    result_list = []\n",
    "    for row in range(len(dataframe)):\n",
    "        if dataframe.loc[row,'RTL_CHANNEL_DSC'] == 'DISTRIBUTOR/SUB-DISTRIBUTOR' or dataframe.loc[row,'RTL_CHANNEL_DSC'] == 'EXTENDED MASTER OFF-PREMISE':\n",
    "            result_list.append(False)\n",
    "        else:\n",
    "            result_list.append(True)\n",
    "    return result_list\n",
    "\n",
    "#save the Oklahoma business rule into pickle\n",
    "pickle.dump(Rules_Oklahoma, open('Oklahoma_business_rule.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#business rule pickle Colorado\n",
    "def Rules_Colorado(dataframe):\n",
    "    result_list = []\n",
    "    for row in range(len(dataframe)):\n",
    "        if dataframe.loc[row,'RTL_PREMISE_TYPE_CD'] == 'OFF':\n",
    "            if dataframe.loc[row,'RTL_CHANNEL_DSC'] == 'LIQUOR' or dataframe.loc[row,'RTL_CHANNEL_DSC'] == 'DRUG' or dataframe.loc[row,'RTL_CHANNEL_DSC'] == 'MILITARY OFF-PREMISE':\n",
    "                result_list.append(False)\n",
    "            elif dataframe.loc[row,'RTL_CHANNEL_DSC'] == 'GROCERY':\n",
    "                if dataframe.loc[row,'RTL_LIQUOR_FLG'] == 'Y':\n",
    "                    result_list.append(False)\n",
    "                else:\n",
    "                    result_list.append(True)\n",
    "            else:\n",
    "                result_list.append(True)\n",
    "        else:\n",
    "             result_list.append(False)\n",
    "    return result_list\n",
    "\n",
    "#save the Colorado business rule into pickle\n",
    "pickle.dump(Rules_Colorado, open('Colorado_business_rule.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decision_tree_pickle_32(classification_df, state):\n",
    "\n",
    "    #call the binarize function to transform the columns into binary\n",
    "    columns = [c for c in classification_df.columns if c not in ['RTL_STORE_CD','LowPoint_Y', 'RTL_STATE_DSC']]\n",
    "    result_df = pd.concat([classification_df, pd.get_dummies(classification_df[columns] , prefix = ['B_'+c for c in columns])] , axis = 1)\n",
    "        \n",
    "    #load the model from pickle for that state\n",
    "    filename = str(state).title()+'_decision_tree_model.p'\n",
    "    decision_tree_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    #prepare independent variables:\n",
    "    X_labels = [c for c in result_df.columns if c not in list(classification_df.columns)]\n",
    "    X = result_df.loc[:,X_labels]\n",
    "\n",
    "    #dependent variable:\n",
    "    result_df['LowPoint_Y'] = decision_tree_model.predict(X) == 'LowPoint'\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Kansas Decision tree Pickle\n",
    "# Load the data\n",
    "data_dir = 'Data/'\n",
    "Stores = pd.read_csv(data_dir + 'AllStoresKansas.csv', dtype = str)\n",
    "StoreType = pd.read_csv(data_dir + 'NonLowPointStoresKansas.csv', dtype = str)\n",
    "FullData = pd.merge(Stores, StoreType, on=\"RTL_STORE_CD\", how=\"left\")\n",
    "FullData.loc[FullData['BEERTYPE'].isnull(),\"BEERTYPE\"] = \"LowPoint\"\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_FIPS_COUNTY_DSC'],prefix='COUNTY')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_PREMISE_TYPE_CD'],prefix='PREMISE')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_CHANNEL_DSC'],prefix='CHANNEL')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_SUBCHANNEL_DSC'],prefix='SUBCHANNEL')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_BEER_FLAG'],prefix='BEER_LICENSE')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_LIQUOR_FLG'],prefix='LIQUOR_LICENSE')], axis=1)\n",
    "\n",
    "# prepare data to fit model\n",
    "X_labels = [c for c in FullData.columns if c not in ['RTL_STORE_CD','BEERTYPE','RTL_FIPS_COUNTY_DSC','RTL_PREMISE_TYPE_CD','RTL_CHANNEL_DSC','RTL_SUBCHANNEL_DSC','RTL_BEER_FLAG',\"RTL_LIQUOR_FLG\"]]\n",
    "X = FullData.loc[:,X_labels]\n",
    "Y = FullData['BEERTYPE']\n",
    "\n",
    "decision_tree_train_and_fit(X, Y, 'Kansas')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minnesota Decision tree Pickle\n",
    "data_dir = 'Data/'\n",
    "Stores = pd.read_csv(data_dir + 'AllStoresMinnesota.csv', dtype = str)\n",
    "StoreType = pd.read_csv(data_dir + 'NonLowPointStoresMinnesota.csv', dtype = str)\n",
    "\n",
    "FullData = pd.merge(Stores, StoreType, on=\"RTL_STORE_CD\", how=\"left\")\n",
    "FullData.loc[FullData['BEERTYPE'].isnull(),\"BEERTYPE\"] = \"LowPoint\"\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_FIPS_COUNTY_DSC'],prefix='COUNTY')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_PREMISE_TYPE_CD'],prefix='PREMISE')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_CHANNEL_DSC'],prefix='CHANNEL')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_SUBCHANNEL_DSC'],prefix='SUBCHANNEL')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_BEER_FLAG'],prefix='BEER_LICENSE')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_LIQUOR_FLG'],prefix='LIQUOR_LICENSE')], axis=1)\n",
    "# prepare data to fit model\n",
    "X_labels = [c for c in FullData.columns if c not in ['RTL_STORE_CD','BEERTYPE','RTL_FIPS_COUNTY_DSC','RTL_PREMISE_TYPE_CD','RTL_CHANNEL_DSC','RTL_SUBCHANNEL_DSC','RTL_BEER_FLAG',\"RTL_LIQUOR_FLG\"]]\n",
    "X = FullData.loc[:,X_labels]\n",
    "Y = FullData['BEERTYPE']\n",
    "\n",
    "decision_tree_train_and_fit(X, Y, 'Minnesota')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decision_tree_train_and_fit(X_train, Y_train, state):\n",
    "\n",
    "    #train the model, and find the best parameter\n",
    "    parameters = {'max_depth':range(1,21), 'min_samples_leaf':range(3,21,3), 'min_samples_split':range(3,21,3), 'random_state': [0]}\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = GridSearchCV(clf, parameters, n_jobs = -2)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    accuracy = clf.best_score_ \n",
    "    best_params = clf.best_params_\n",
    "    best_depth = best_params['max_depth']\n",
    "    best_leaf = best_params['min_samples_leaf']\n",
    "    best_split = best_params['min_samples_split']\n",
    "\n",
    "    #using the best parameter to train and fit the model\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=best_depth, min_samples_leaf= best_leaf, min_samples_split = best_split, random_state=0)\n",
    "    clf = clf.fit(X_train,Y_train)\n",
    "    \n",
    "    filename = str(state).title()+'_decision_tree_model.p'\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
