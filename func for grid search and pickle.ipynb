{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "from IPython.display import IFrame    #to display pdf file\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RTL_STORE_CD</th>\n",
       "      <th>RTL_FIPS_COUNTY_DSC</th>\n",
       "      <th>RTL_PREMISE_TYPE_CD</th>\n",
       "      <th>RTL_CHANNEL_DSC</th>\n",
       "      <th>RTL_SUBCHANNEL_DSC</th>\n",
       "      <th>RTL_BEER_FLAG</th>\n",
       "      <th>RTL_LIQUOR_FLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101403888</td>\n",
       "      <td>SEDGWICK</td>\n",
       "      <td>OFF</td>\n",
       "      <td>LIQUOR</td>\n",
       "      <td>CONVENTIONAL LIQUOR</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100091604</td>\n",
       "      <td>SALINE</td>\n",
       "      <td>OFF</td>\n",
       "      <td>CONVENIENCE STORE</td>\n",
       "      <td>CONVENTIONAL CONVENIENCE</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200697901</td>\n",
       "      <td>SEDGWICK</td>\n",
       "      <td>OFF</td>\n",
       "      <td>CONVENIENCE STORE</td>\n",
       "      <td>CONVENTIONAL CONVENIENCE</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100091143</td>\n",
       "      <td>HARPER</td>\n",
       "      <td>OFF</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>SUPERMARKET-CONVENTIONAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107381463</td>\n",
       "      <td>DOUGLAS</td>\n",
       "      <td>OFF</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>SUPERMARKET-NATURAL/GOURMET FOODS</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RTL_STORE_CD RTL_FIPS_COUNTY_DSC RTL_PREMISE_TYPE_CD    RTL_CHANNEL_DSC  \\\n",
       "0    101403888            SEDGWICK                 OFF             LIQUOR   \n",
       "1    100091604              SALINE                 OFF  CONVENIENCE STORE   \n",
       "2    200697901            SEDGWICK                 OFF  CONVENIENCE STORE   \n",
       "3    100091143              HARPER                 OFF            GROCERY   \n",
       "4    107381463             DOUGLAS                 OFF            GROCERY   \n",
       "\n",
       "                  RTL_SUBCHANNEL_DSC RTL_BEER_FLAG RTL_LIQUOR_FLG  \n",
       "0                CONVENTIONAL LIQUOR             Y              Y  \n",
       "1           CONVENTIONAL CONVENIENCE             Y              N  \n",
       "2           CONVENTIONAL CONVENIENCE             Y              N  \n",
       "3           SUPERMARKET-CONVENTIONAL             Y              N  \n",
       "4  SUPERMARKET-NATURAL/GOURMET FOODS             Y              N  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "data_dir = 'Data/'\n",
    "Stores = pd.read_csv(data_dir + 'AllStoresKansas.csv', dtype = str)\n",
    "StoreType = pd.read_csv(data_dir + 'NonLowPointStoresKansas.csv', dtype = str)\n",
    "KansasCounties = pd.read_csv(data_dir + 'KansasCounties.csv', dtype = str)\n",
    "Stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'RTL_STORE_CD', u'RTL_FIPS_COUNTY_DSC', u'RTL_PREMISE_TYPE_CD',\n",
       "       u'RTL_CHANNEL_DSC', u'RTL_SUBCHANNEL_DSC', u'RTL_BEER_FLAG',\n",
       "       u'RTL_LIQUOR_FLG', u'RTL_STATE_DSC', u'LowPoint_Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stores['RTL_STATE_DSC'] = 'KANSAS'\n",
    "Stores['LowPoint_Y'] = ''\n",
    "Stores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALLEN</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>MIXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>MIXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATCHISON</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>MIXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BARBER</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>WET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BARTON</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td>WET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     COUNTY    STATE STATUS\n",
       "0     ALLEN   KANSAS  MIXED\n",
       "1  ANDERSON   KANSAS  MIXED\n",
       "2  ATCHISON   KANSAS  MIXED\n",
       "3    BARBER   KANSAS    WET\n",
       "4    BARTON   KANSAS    WET"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KansasCounties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#convert the column name into capitalized \n",
    "StoreType.columns = [x.upper() for x in StoreType.columns]\n",
    "Stores.columns = [x.upper() for x in Stores.columns]\n",
    "KansasCounties.columns = [x.upper() for x in KansasCounties.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RTL_STORE_CD</th>\n",
       "      <th>RTL_FIPS_COUNTY_DSC</th>\n",
       "      <th>RTL_PREMISE_TYPE_CD</th>\n",
       "      <th>RTL_CHANNEL_DSC</th>\n",
       "      <th>RTL_SUBCHANNEL_DSC</th>\n",
       "      <th>RTL_BEER_FLAG</th>\n",
       "      <th>RTL_LIQUOR_FLG</th>\n",
       "      <th>RTL_STATE_DSC</th>\n",
       "      <th>LowPoint_Y</th>\n",
       "      <th>BEERTYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>SUBCHANNEL_SUPERMARKET-NATURAL/GOURMET FOODS</th>\n",
       "      <th>SUBCHANNEL_THEATER</th>\n",
       "      <th>SUBCHANNEL_UNKNOWN</th>\n",
       "      <th>SUBCHANNEL_WINE SPECIALTY STORE</th>\n",
       "      <th>BEER_LICENSE_N</th>\n",
       "      <th>BEER_LICENSE_U</th>\n",
       "      <th>BEER_LICENSE_Y</th>\n",
       "      <th>LIQUOR_LICENSE_N</th>\n",
       "      <th>LIQUOR_LICENSE_U</th>\n",
       "      <th>LIQUOR_LICENSE_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101403888</td>\n",
       "      <td>SEDGWICK</td>\n",
       "      <td>OFF</td>\n",
       "      <td>LIQUOR</td>\n",
       "      <td>CONVENTIONAL LIQUOR</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td></td>\n",
       "      <td>NonLowPoint</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100091604</td>\n",
       "      <td>SALINE</td>\n",
       "      <td>OFF</td>\n",
       "      <td>CONVENIENCE STORE</td>\n",
       "      <td>CONVENTIONAL CONVENIENCE</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td></td>\n",
       "      <td>LowPoint</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200697901</td>\n",
       "      <td>SEDGWICK</td>\n",
       "      <td>OFF</td>\n",
       "      <td>CONVENIENCE STORE</td>\n",
       "      <td>CONVENTIONAL CONVENIENCE</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td></td>\n",
       "      <td>LowPoint</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100091143</td>\n",
       "      <td>HARPER</td>\n",
       "      <td>OFF</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>SUPERMARKET-CONVENTIONAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td></td>\n",
       "      <td>LowPoint</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107381463</td>\n",
       "      <td>DOUGLAS</td>\n",
       "      <td>OFF</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>SUPERMARKET-NATURAL/GOURMET FOODS</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>KANSAS</td>\n",
       "      <td></td>\n",
       "      <td>LowPoint</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  RTL_STORE_CD RTL_FIPS_COUNTY_DSC RTL_PREMISE_TYPE_CD    RTL_CHANNEL_DSC  \\\n",
       "0    101403888            SEDGWICK                 OFF             LIQUOR   \n",
       "1    100091604              SALINE                 OFF  CONVENIENCE STORE   \n",
       "2    200697901            SEDGWICK                 OFF  CONVENIENCE STORE   \n",
       "3    100091143              HARPER                 OFF            GROCERY   \n",
       "4    107381463             DOUGLAS                 OFF            GROCERY   \n",
       "\n",
       "                  RTL_SUBCHANNEL_DSC RTL_BEER_FLAG RTL_LIQUOR_FLG  \\\n",
       "0                CONVENTIONAL LIQUOR             Y              Y   \n",
       "1           CONVENTIONAL CONVENIENCE             Y              N   \n",
       "2           CONVENTIONAL CONVENIENCE             Y              N   \n",
       "3           SUPERMARKET-CONVENTIONAL             Y              N   \n",
       "4  SUPERMARKET-NATURAL/GOURMET FOODS             Y              N   \n",
       "\n",
       "  RTL_STATE_DSC LowPoint_Y     BEERTYPE        ...         \\\n",
       "0        KANSAS             NonLowPoint        ...          \n",
       "1        KANSAS                LowPoint        ...          \n",
       "2        KANSAS                LowPoint        ...          \n",
       "3        KANSAS                LowPoint        ...          \n",
       "4        KANSAS                LowPoint        ...          \n",
       "\n",
       "   SUBCHANNEL_SUPERMARKET-NATURAL/GOURMET FOODS  SUBCHANNEL_THEATER  \\\n",
       "0                                             0                   0   \n",
       "1                                             0                   0   \n",
       "2                                             0                   0   \n",
       "3                                             0                   0   \n",
       "4                                             1                   0   \n",
       "\n",
       "   SUBCHANNEL_UNKNOWN  SUBCHANNEL_WINE SPECIALTY STORE  BEER_LICENSE_N  \\\n",
       "0                   0                                0               0   \n",
       "1                   0                                0               0   \n",
       "2                   0                                0               0   \n",
       "3                   0                                0               0   \n",
       "4                   0                                0               0   \n",
       "\n",
       "   BEER_LICENSE_U  BEER_LICENSE_Y  LIQUOR_LICENSE_N  LIQUOR_LICENSE_U  \\\n",
       "0               0               1                 0                 0   \n",
       "1               0               1                 1                 0   \n",
       "2               0               1                 1                 0   \n",
       "3               0               1                 1                 0   \n",
       "4               0               1                 1                 0   \n",
       "\n",
       "   LIQUOR_LICENSE_Y  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "\n",
       "[5 rows x 211 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FullData = pd.merge(Stores, StoreType, on=\"RTL_STORE_CD\", how=\"left\")\n",
    "FullData.loc[FullData['BEERTYPE'].isnull(),\"BEERTYPE\"] = \"LowPoint\"\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_FIPS_COUNTY_DSC'],prefix='COUNTY')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_PREMISE_TYPE_CD'],prefix='PREMISE')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_CHANNEL_DSC'],prefix='CHANNEL')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_SUBCHANNEL_DSC'],prefix='SUBCHANNEL')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_BEER_FLAG'],prefix='BEER_LICENSE')], axis=1)\n",
    "FullData = pd.concat([FullData, pd.get_dummies(FullData['RTL_LIQUOR_FLG'],prefix='LIQUOR_LICENSE')], axis=1)\n",
    "FullData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the columns in pickle\n",
    "columns = list(Stores.columns)\n",
    "\n",
    "raw_columns = 'classification_columns.p'\n",
    "pickle.dump(columns, open('classification_columns.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for production whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save this one \n",
    "def classify_32(self, state, isPickle):\n",
    "    \n",
    "    '''\n",
    "    This function takes in dataframe, and classify the store type to either it is a LowPoint store or not.\n",
    "        LowPoint_Y = True: stores that can only sell 3.2% beer.\n",
    "        LowPoint_Y = False: stores that can sell any beer.\n",
    "    \n",
    "    Parameter:\n",
    "    ---------\n",
    "        state: takes a string. Indicates the state.\n",
    "        isPickle: takes a boolean. Indicates classification method. 'True' for pickle, 'False' for grid search\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "        the dataframe with prediction result under 'LowPoint_Y' column.\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    #define a function to get the subset of dataframe\n",
    "    def classification_subset(self, state):\n",
    "\n",
    "        '''\n",
    "        This function subsets the dataframe to prepare classification.\n",
    "\n",
    "        parameter:\n",
    "        ---------\n",
    "            state: Takes a string. The name of state to subset dataframe. \n",
    "            \n",
    "        return:\n",
    "        -------\n",
    "            The subsetted dataframe.        \n",
    "        '''\n",
    "\n",
    "        #load the columns for subset from pickle:\n",
    "        subset_columns = pickle.load(open('classification_columns.p', 'rb'))\n",
    "\n",
    "        #subset the dataframe:\n",
    "        classification_df = pd.DataFrame(self.data[subset_columns])\n",
    "\n",
    "        classification_df = classification_df[classification_df['RTL_STATE_DSC'] == str(state).upper()]\n",
    "\n",
    "        \n",
    "    \n",
    "    #define a function to run pickle for decision tree model. \n",
    "    def decision_tree_pickle(self, classification_df, state):\n",
    "\n",
    "        '''\n",
    "        This function takes the name of the state, and using the subsetted dataframe from function 'classification_subset' \n",
    "            to classify the stores using pickled decision tree model. \n",
    "\n",
    "        parameter:\n",
    "        ----------\n",
    "            classification_df: Takes a dataframe. The subsetted dataframe after excuting the function \"classification_subset\"\n",
    "            state: Takes a string. The name of the State\n",
    "\n",
    "        return:\n",
    "        -------\n",
    "            The dataframe with prediction result.        \n",
    "        '''\n",
    "        #call the binarize function to transform the columns into binary\n",
    "        result_df = self.binarize([c for c in classification_df.columns if c not in ['RTL_STORE_CD',\"LowPoint_Y\"]])\n",
    "\n",
    "        #load the model from pickle for that state\n",
    "        filename = str(state).title()+'_decision_tree_model.p'\n",
    "        decision_tree_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "        #prepare independent variables:\n",
    "        X_labels = [c for c in result_df.columns if c not in [classification_df.columns]]\n",
    "        X = result_df.loc[:,X_labels]\n",
    "\n",
    "        #dependent variable:\n",
    "        result_df['LowPoint_Y'] = decision_tree_model.predict(X) == 'LowPoint'\n",
    "        \n",
    "    #define a function to run pickle for business rule. \n",
    "    def business_rule_pickle(self, classification_df, state):\n",
    "        '''\n",
    "        This function takes the name of the state, and using the subsetted dataframe from function 'classification_subset' \n",
    "            to classify the stores using pickled business rule.\n",
    "\n",
    "        parameter:\n",
    "        ----------\n",
    "            state: Takes a string. The name of the State\n",
    "            classification_df: Takes a dataframe. The subsetted dataframe after excuting the function \"classification_subset\"\n",
    "\n",
    "        return:\n",
    "        -------\n",
    "            The dataframe with prediction result.        \n",
    "        '''    \n",
    "\n",
    "        #load the business rule from pickle for that State\n",
    "        filename = str(state).title()+'_business_rule.p'\n",
    "        rule_func = pickle.load(open('filename.p', 'rb'))\n",
    "\n",
    "        #make the prediction\n",
    "        rule_func(classification_df)\n",
    "\n",
    "    def read_query_and_predict(self, classification_df, state):\n",
    "    \n",
    "        '''\n",
    "        This function queries from Oracle SQL for specific state and store type and save the data in a dataframe. Then, use decision\n",
    "            tree classifier to train the labeled data, and make prediction on whole dataset.\n",
    "\n",
    "        parameter:\n",
    "        ---------\n",
    "            classification_df: Takes a dataframe. The subsetted dataframe after excuting the function \"classification_subset\"\n",
    "            state: Takes a string. The state name\n",
    "\n",
    "        return:\n",
    "        -------\n",
    "            a dataframe with prediction result. \n",
    "        '''\n",
    "\n",
    "\n",
    "        #Access to Oracle DB\n",
    "        host = 'tncluster6.cbi.net'\n",
    "        port = 1521\n",
    "        s_name = 'EDW1TS_EX.cbi.net'\n",
    "        dsn_tns = cx_Oracle.makedsn(host, port, service_name = s_name)\n",
    "        db_ts = cx_Oracle.connect('USERNAME', 'PASSWORD', dsn_tns)\n",
    "        cursor = db_ts.cursor()\n",
    "\n",
    "        if str(state) == 'Kansas'.casefold():\n",
    "            state_code = str(162)\n",
    "        elif str(state) == 'Utah'.casefold():\n",
    "            state_code = str(239)\n",
    "        elif str(state) == 'Minnesota'.casefold():\n",
    "            state_code = str(177)\n",
    "        elif str(state) == 'Corolado'.casefold():\n",
    "            state_code = str(125)\n",
    "        elif str(state) == 'Oklahoma'.casefold():\n",
    "            state_code = str(201)\n",
    "\n",
    "        query = '''select /*+ parallel(6) */ a15.STORE_CD  RTL_STORE_CD, 'NonLowPoint' as \"BEERTYPE\"\n",
    "                    from EDW.BI_CRN_F_RETAIL_DEPL_MVW_VW a11\n",
    "                    join EDW.BI_CRN_D_ITEM_VW a12\n",
    "                       on  (a11.ITEM_ID = a12.ITEM_ID)\n",
    "                     join EDW.BI_CRN_D_REL_TIME_DETAIL_VW a13\n",
    "                       on  (a11.DATE_ID = a13.REL_DATE_ID)\n",
    "                     join EDW.BI_CRN_D_DISTRIBUTOR_VW a14\n",
    "                       on  (a11.DIST_ID = a14.DIST_ID)\n",
    "                     join EDW.BI_CRN_D_RETAILER_VW a15\n",
    "                       on  (a11.RETAILER_ID = a15.RETAILER_ID)\n",
    "                    where (a13.REL_TIME_CD in ('L3_TY')\n",
    "                     and a14.STATE_PROVINCE_COUNTRY_CD in (''' + \"'\" + state_code + \"')\" + ''' and a12.MASTER_SKU_CD not in ('80013450', '80013452', '80013455', '80013979', '80013456', '80013475', '80061325', '80013477', '80013982', '80013980', '80059842', '80058839', '80014020', '80014022', '80014023', '80014024', '80014025', '80013992', '80013991', '80013464', '80013466', '80013469', '80013471', '80013472', '80013473', '80013478', '80031998', '80013485', '80056926', '80058838', '80019746', '80031994', '80015966', '80014017', '80012704', '80014015', '80014009', '80014011', '80024732', '80013994', '80056172', '80014010'))\n",
    "                    group by a15.STORE_CD\n",
    "                    UNION \n",
    "                    select /*+ parallel(6) */ a15.STORE_CD  RTL_STORE_CD,\n",
    "                     'LowPoint' as \"BEERTYPE\"\n",
    "                    from EDW.BI_CRN_F_RETAIL_DEPL_MVW_VW a11\n",
    "                     join EDW.BI_CRN_D_ITEM_VW a12\n",
    "                       on  (a11.ITEM_ID = a12.ITEM_ID)\n",
    "                     join EDW.BI_CRN_D_REL_TIME_DETAIL_VW a13\n",
    "                       on  (a11.DATE_ID = a13.REL_DATE_ID)\n",
    "                     join EDW.BI_CRN_D_DISTRIBUTOR_VW a14\n",
    "                       on  (a11.DIST_ID = a14.DIST_ID)\n",
    "                     join EDW.BI_CRN_D_RETAILER_VW a15\n",
    "                       on  (a11.RETAILER_ID = a15.RETAILER_ID)\n",
    "                    where (a13.REL_TIME_CD in ('L3_TY')\n",
    "                     and a14.STATE_PROVINCE_COUNTRY_CD in (''' +\"'\" + state_code + \"')\" + ''' and a12.MASTER_SKU_CD not in ('80029020', '80060325', '80032234', '80032233', '80023100', '80031072', '80013435', '80013437', '80013439', '80057078', '80014016', '80013442', '80026873', '80056799', '80013444', '80014014', '80013447', '80013460', '80013457', '80013458', '80059543', '80013461', '80059542', '80059571', '80059572', '80059573', '80013982', '80013980', '80056922', '80014002', '80013968', '80029050', '80013515', '80013516', '80013517', '80013518', '80018933', '80056908', '80013520', '80014006', '80013993', '80013522', '80014026', '80013984', '80013978', '80013970', '80014012', '80014060', '80013986', '80013977', '80060330', '80060331', '80060328', '999', '80014008', '80013995', '80013972', '80056887', '80014001', '80031989', '80013985', '80013971', '80013983', '80014007', '80029021', '80015214', '80015215', '80014005', '80014004', '80013976', '80013990', '80013998', '80013989', '80013975', '80013997', '80027630', '80027631', '80027632', '80062390', '80062550', '80013996', '80014013', '80013988', '80013987', '80013974', '80013973', '80013999', '80014000', 'UNK', '80013981'))\n",
    "                    group by a15.STORE_CD '''\n",
    "\n",
    "        try:\n",
    "            cursor.execute(query)\n",
    "            names = [ x[0] for x in cursor.description]\n",
    "            rows = cursor.fetchall()\n",
    "            StoreType = pd.DataFrame( rows, columns=names)\n",
    "\n",
    "        finally:\n",
    "            if cursor is not None:\n",
    "                cursor.close()\n",
    "\n",
    "        #If the above code runs sucessfully, it will return a dataframe which columns: store number and store type(LowPoint or NonLowPoint)\n",
    "\n",
    "\n",
    "\n",
    "        #left join the store type data with subsetted dataframe\n",
    "        result_df = pd.merge(classification_df, StoreType, on=\"RTL_STORE_CD\", how=\"left\")  \n",
    "\n",
    "        #call the binarize function to transform the columns into binary\n",
    "        result_df = self.binarize([c for c in classification_df.columns if c not in ['RTL_STORE_CD',\"LowPoint_Y\"]])\n",
    "\n",
    "        #subset the training dataset\n",
    "        train_df = result_df.loc[result_df['BEERTYPE'] != '']  \n",
    "\n",
    "        #fit the model using traning data\n",
    "        #independent variables:\n",
    "        X_labels = [c for c in train_df.columns if c not in [classification_df.columns]]\n",
    "        X_train = train_df.loc[:,X_labels]\n",
    "        #dependent variable:\n",
    "        Y_train = train_df.loc['BEERTYPE'] \n",
    "\n",
    "        #train the model, and find the best parameter\n",
    "        parameters = {'max_depth':range(1,21), 'min_samples_leaf':range(3,21,3), 'min_samples_split':range(3,21,3), 'random_state': [0]}\n",
    "        clf = tree.DecisionTreeClassifier()\n",
    "        clf = GridSearchCV(clf, parameters, n_jobs = -2)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        accuracy = clf.best_score_ \n",
    "        best_params = clf.best_params_\n",
    "        best_depth = best_params['max_depth']\n",
    "        best_leaf = best_params['min_samples_leaf']\n",
    "        best_split = best_params['min_samples_split']\n",
    "\n",
    "        #using the best parameter to train and fit the model\n",
    "        clf = tree.DecisionTreeClassifier(max_depth=best_depth, min_samples_leaf= best_leaf, min_samples_split = best_split, random_state=0)\n",
    "        clf = clf.fit(X_train,Y_train)\n",
    "\n",
    "        #Prepare for prediction dataset\n",
    "        X_pred = result_df.loc[:,X_labels]\n",
    "\n",
    "        #make prediction for whole dataset.\n",
    "        result_df['LowPoint_Y'] = clf.predict(X_pred) == 'LowPoint_Y'        \n",
    "\n",
    "        #delete the column 'BEERTYPE'\n",
    "        del result_df['BEERTYPE']    \n",
    "     \n",
    "    \n",
    "    \n",
    "    ###############################excute code########################\n",
    "    \n",
    "    #create a LowPoint_Y column for entire dataset. \n",
    "    self.data['LowPoint_Y'] = ''\n",
    "    \n",
    "    #take a subset of the data classification_subset \n",
    "    classification_df = self.classification_subset(self.data)\n",
    "    \n",
    "    #if using Pickle\n",
    "    if isPickle:\n",
    "        \n",
    "        #Decision tree model for Kansas and Minnesota\n",
    "        #If the state is Kansas:\n",
    "        if state == 'Kansas'.casefold():\n",
    "            self.decision_tree_pickle(classification_df, 'Kansas')\n",
    "\n",
    "        #If the state is Minnesota:   \n",
    "        elif state == 'Minnesota'.casefold():\n",
    "            self.decision_tree_pickle(classification_df, 'Minnesota')\n",
    "      \n",
    "    \n",
    "        #Business rule for Utah, Oklahoma, and Colorado\n",
    "        #If the state is Utah:\n",
    "        elif state == 'Utah'.casefold():\n",
    "            self.business_rule_pickle(classification_df, 'Utah')\n",
    "            \n",
    "        #If the state is Oklahoma:   \n",
    "        elif state == 'Oklahoma'.casefold():\n",
    "            self.business_rule_pickle(classification_df, 'Oklahoma')\n",
    "\n",
    "\n",
    "        #If the state is Colorado:  \n",
    "        elif state == 'Colorado'.casefold():\n",
    "            self.business_rule_pickle(classification_df, 'Colorado')\n",
    "\n",
    "        #If enter other States:\n",
    "        else:\n",
    "            print('wrong state')\n",
    "            break\n",
    "    \n",
    "    #if using grid search\n",
    "    else:\n",
    "        \n",
    "        #If the state is Kansas:\n",
    "        if state == 'Kansas'.casefold():\n",
    "            #get the query result as dataframe and get the prediction result\n",
    "            self.read_query_and_predict(classification_df, 'Kansas')\n",
    "        \n",
    "        #If the state is Minnesota:    \n",
    "        elif state == 'Minnesota'.casefold():\n",
    "            #get the query result as dataframe and get the prediction result\n",
    "            self.read_query_and_predict(classification_df, 'Minnesota')\n",
    "\n",
    "        else:\n",
    "            print('wrong state')\n",
    "            break \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function to get the subset of dataframe\n",
    "def classification_subset_32(self, state):   #classification_subset_32\n",
    "                                            #want the ab. version of state, not entire name\n",
    "        \n",
    "    '''\n",
    "    This function subsets the dataframe to prepare classification.\n",
    "    \n",
    "    parameter:\n",
    "    ---------\n",
    "        state: Takes a string. The name of state to subset dataframe. \n",
    "        \n",
    "    return:\n",
    "    -------\n",
    "        The subsetted dataframe.        \n",
    "    '''\n",
    "\n",
    "    #load the columns for subset from pickle:\n",
    "    subset_columns = pickle.load(open('classification_columns.p', 'rb'))\n",
    "    \n",
    "    #subset the dataframe:\n",
    "    classification_df = pd.DataFrame(self.data[subset_columns])\n",
    "    \n",
    "    classification_df = classification_df[classification_df['RTL_STATE_DSC'] == str(state).upper()]\n",
    "    #state will pull from market_cd\n",
    "    \n",
    "    \n",
    "    \n",
    "    #create a LowPoint_Y column to store the result. \n",
    "    classification_df['LowPoint_Y'] = ''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function to run pickle for decision tree model. \n",
    "def decision_tree_pickle_32(self, classification_df, state):   #decision_tree_pickle_32\n",
    "    \n",
    "    '''\n",
    "    This function takes the name of the state, and using the subsetted dataframe from function 'classification_subset' \n",
    "        to classify the stores using pickled decision tree model. \n",
    "        \n",
    "    parameter:\n",
    "    ----------\n",
    "        classification_df: Takes a dataframe. The subsetted dataframe after excuting the function \"classification_subset\"\n",
    "        state: Takes a string. The name of the State\n",
    "        \n",
    "    return:\n",
    "    -------\n",
    "        The dataframe with prediction result.        \n",
    "    '''\n",
    "    #call the binarize function to transform the columns into binary\n",
    "    result_df = self.binarize([c for c in classification_df.columns if c not in ['RTL_STORE_CD',\"LowPoint_Y\"]])\n",
    "    #check here.\n",
    "    \n",
    "    #load the model from pickle for that state\n",
    "    filename = str(state).title()+'_decision_tree_model.p'\n",
    "    decision_tree_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    #prepare independent variables:\n",
    "    X_labels = [c for c in result_df.columns if c not in [classification_df.columns]]\n",
    "    X = result_df.loc[:,X_labels]\n",
    "\n",
    "    #dependent variable:\n",
    "    result_df['LowPoint_Y'] = decision_tree_model.predict(X) == 'LowPoint'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function to run pickle for business rule. \n",
    "def business_rule_pickle(self, classification_df, state):\n",
    "    '''\n",
    "    This function takes the name of the state, and using the subsetted dataframe from function 'classification_subset' \n",
    "        to classify the stores using pickled business rule.\n",
    "    \n",
    "    parameter:\n",
    "    ----------\n",
    "        state: Takes a string. The name of the State\n",
    "        classification_df: Takes a dataframe. The subsetted dataframe after excuting the function \"classification_subset\"\n",
    "        \n",
    "    return:\n",
    "    -------\n",
    "        The dataframe with prediction result.        \n",
    "    '''    \n",
    "\n",
    "    #load the business rule from pickle for that State\n",
    "    filename = str(state).title()+'_business_rule.p'\n",
    "    rule_func = pickle.load(open('filename.p', 'rb'))\n",
    "\n",
    "    #make the prediction\n",
    "    rule_func(classification_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function to get the sql query.\n",
    "#Kansas: 162\n",
    "#Utah:239\n",
    "#Minnesota:177\n",
    "#Corolado:125\n",
    "#Oklahoma:201\n",
    "\n",
    "\n",
    "def read_query_and_predict(self, classification_df, state):\n",
    "    \n",
    "    '''\n",
    "    This function queries from Oracle SQL for specific state and store type and save the data in a dataframe. Then, use decision\n",
    "        tree classifier to train the labeled data, and make prediction on whole dataset.\n",
    "    \n",
    "    parameter:\n",
    "    ---------\n",
    "        classification_df: Takes a dataframe. The subsetted dataframe after excuting the function \"classification_subset\"\n",
    "        state: Takes a string. The state name\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "        a dataframe with prediction result. \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    #Access to Oracle DB\n",
    "    host = 'tncluster6.cbi.net'\n",
    "    port = 1521\n",
    "    s_name = 'EDW1TS_EX.cbi.net'\n",
    "    dsn_tns = cx_Oracle.makedsn(host, port, service_name = s_name)\n",
    "    db_ts = cx_Oracle.connect('USERNAME', 'PASSWORD', dsn_tns)\n",
    "    cursor = db_ts.cursor()\n",
    "    \n",
    "    if str(state) == 'Kansas'.casefold():\n",
    "        state_code = str(162)\n",
    "    elif str(state) == 'Utah'.casefold():\n",
    "        state_code = str(239)\n",
    "    elif str(state) == 'Minnesota'.casefold():\n",
    "        state_code = str(177)\n",
    "    elif str(state) == 'Corolado'.casefold():\n",
    "        state_code = str(125)\n",
    "    elif str(state) == 'Oklahoma'.casefold():\n",
    "        state_code = str(201)\n",
    "    \n",
    "    query = '''select /*+ parallel(6) */ a15.STORE_CD  RTL_STORE_CD, 'NonLowPoint' as \"BEERTYPE\"\n",
    "                from EDW.BI_CRN_F_RETAIL_DEPL_MVW_VW a11\n",
    "                join EDW.BI_CRN_D_ITEM_VW a12\n",
    "                   on  (a11.ITEM_ID = a12.ITEM_ID)\n",
    "                 join EDW.BI_CRN_D_REL_TIME_DETAIL_VW a13\n",
    "                   on  (a11.DATE_ID = a13.REL_DATE_ID)\n",
    "                 join EDW.BI_CRN_D_DISTRIBUTOR_VW a14\n",
    "                   on  (a11.DIST_ID = a14.DIST_ID)\n",
    "                 join EDW.BI_CRN_D_RETAILER_VW a15\n",
    "                   on  (a11.RETAILER_ID = a15.RETAILER_ID)\n",
    "                where (a13.REL_TIME_CD in ('L3_TY')\n",
    "                 and a14.STATE_PROVINCE_COUNTRY_CD in (''' + \"'\" + state_code + \"')\" + ''' and a12.MASTER_SKU_CD not in ('80013450', '80013452', '80013455', '80013979', '80013456', '80013475', '80061325', '80013477', '80013982', '80013980', '80059842', '80058839', '80014020', '80014022', '80014023', '80014024', '80014025', '80013992', '80013991', '80013464', '80013466', '80013469', '80013471', '80013472', '80013473', '80013478', '80031998', '80013485', '80056926', '80058838', '80019746', '80031994', '80015966', '80014017', '80012704', '80014015', '80014009', '80014011', '80024732', '80013994', '80056172', '80014010'))\n",
    "                group by a15.STORE_CD\n",
    "                UNION \n",
    "                select /*+ parallel(6) */ a15.STORE_CD  RTL_STORE_CD,\n",
    "                 'LowPoint' as \"BEERTYPE\"\n",
    "                from EDW.BI_CRN_F_RETAIL_DEPL_MVW_VW a11\n",
    "                 join EDW.BI_CRN_D_ITEM_VW a12\n",
    "                   on  (a11.ITEM_ID = a12.ITEM_ID)\n",
    "                 join EDW.BI_CRN_D_REL_TIME_DETAIL_VW a13\n",
    "                   on  (a11.DATE_ID = a13.REL_DATE_ID)\n",
    "                 join EDW.BI_CRN_D_DISTRIBUTOR_VW a14\n",
    "                   on  (a11.DIST_ID = a14.DIST_ID)\n",
    "                 join EDW.BI_CRN_D_RETAILER_VW a15\n",
    "                   on  (a11.RETAILER_ID = a15.RETAILER_ID)\n",
    "                where (a13.REL_TIME_CD in ('L3_TY')\n",
    "                 and a14.STATE_PROVINCE_COUNTRY_CD in (''' +\"'\" + state_code + \"')\" + ''' and a12.MASTER_SKU_CD not in ('80029020', '80060325', '80032234', '80032233', '80023100', '80031072', '80013435', '80013437', '80013439', '80057078', '80014016', '80013442', '80026873', '80056799', '80013444', '80014014', '80013447', '80013460', '80013457', '80013458', '80059543', '80013461', '80059542', '80059571', '80059572', '80059573', '80013982', '80013980', '80056922', '80014002', '80013968', '80029050', '80013515', '80013516', '80013517', '80013518', '80018933', '80056908', '80013520', '80014006', '80013993', '80013522', '80014026', '80013984', '80013978', '80013970', '80014012', '80014060', '80013986', '80013977', '80060330', '80060331', '80060328', '999', '80014008', '80013995', '80013972', '80056887', '80014001', '80031989', '80013985', '80013971', '80013983', '80014007', '80029021', '80015214', '80015215', '80014005', '80014004', '80013976', '80013990', '80013998', '80013989', '80013975', '80013997', '80027630', '80027631', '80027632', '80062390', '80062550', '80013996', '80014013', '80013988', '80013987', '80013974', '80013973', '80013999', '80014000', 'UNK', '80013981'))\n",
    "                group by a15.STORE_CD '''\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        names = [ x[0] for x in cursor.description]\n",
    "        rows = cursor.fetchall()\n",
    "        StoreType = pd.DataFrame( rows, columns=names)\n",
    "\n",
    "    finally:\n",
    "        if cursor is not None:\n",
    "            cursor.close()\n",
    "            \n",
    "    #If the above code runs sucessfully, it will return a dataframe which columns: store number and store type(LowPoint or NonLowPoint)\n",
    "    \n",
    "    \n",
    "      \n",
    "    #left join the store type data with subsetted dataframe\n",
    "    result_df = pd.merge(classification_df, StoreType, on=\"RTL_STORE_CD\", how=\"left\")  \n",
    "    \n",
    "    #call the binarize function to transform the columns into binary\n",
    "    result_df = self.binarize([c for c in classification_df.columns if c not in ['RTL_STORE_CD',\"LowPoint_Y\"]])\n",
    "    \n",
    "    #subset the training dataset\n",
    "    train_df = result_df.loc[result_df['BEERTYPE'] != '']  \n",
    "    \n",
    "    #fit the model using traning data\n",
    "    #independent variables:\n",
    "    X_labels = [c for c in train_df.columns if c not in [classification_df.columns]]\n",
    "    X_train = train_df.loc[:,X_labels]\n",
    "    #dependent variable:\n",
    "    Y_train = train_df.loc['BEERTYPE'] \n",
    "    \n",
    "    #train the model, and find the best parameter\n",
    "    parameters = {'max_depth':range(1,21), 'min_samples_leaf':range(3,21,3), 'min_samples_split':range(3,21,3), 'random_state': [0]}\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = GridSearchCV(clf, parameters, n_jobs = -2)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    accuracy = clf.best_score_ \n",
    "    best_params = clf.best_params_\n",
    "    best_depth = best_params['max_depth']\n",
    "    best_leaf = best_params['min_samples_leaf']\n",
    "    best_split = best_params['min_samples_split']\n",
    "\n",
    "    #using the best parameter to train and fit the model\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=best_depth, min_samples_leaf= best_leaf, min_samples_split = best_split, random_state=0)\n",
    "    clf = clf.fit(X_train,Y_train)\n",
    "\n",
    "    #Prepare for prediction dataset\n",
    "    X_pred = result_df.loc[:,X_labels]\n",
    "\n",
    "    #make prediction for whole dataset.\n",
    "    result_df['LowPoint_Y'] = clf.predict(X_pred) == 'LowPoint_Y'        \n",
    "        \n",
    "    #delete the column 'BEERTYPE'\n",
    "    del result_df['BEERTYPE']    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#define a function to run pickle for business rule. \n",
    "def decision_tree_grid():\n",
    "    \n",
    "    '''\n",
    "    This function uses the subsetted dataframe from 'classification_subset' function to classify the stores using grid search.\n",
    "    \n",
    "    parameter:\n",
    "    ----------\n",
    "        None\n",
    "        \n",
    "    return:\n",
    "    -------\n",
    "        The dataframe with prediction result.        \n",
    "    '''      \n",
    "    #merge the store type with original dataframe, and subset the training dataset.\n",
    "    result_df = pd.merge(classification_df, StoreType, on=\"RTL_STORE_CD\", how=\"left\")  \n",
    "    \n",
    "    #call the binarize function to transform the columns into binary\n",
    "    result_df = self.binarize([c for c in classification_df.columns if c not in ['RTL_STORE_CD',\"LowPoint_Y\"]])\n",
    "    \n",
    "    #subset the training dataset\n",
    "    train_df = result_df.loc[result_df['BEERTYPE'] != '']  \n",
    "    \n",
    "    #fit the model using traning data\n",
    "    #independent variables:\n",
    "    X_labels = [c for c in train_df.columns if c not in [classification_df.columns]]\n",
    "    X_train = train_df.loc[:,X_labels]\n",
    "    Y_train = train_df.loc['BEERTYPE'] \n",
    "    \n",
    "    #train the model, and find the best parameter\n",
    "    parameters = {'max_depth':range(1,21), 'min_samples_leaf':range(3,21,3), 'min_samples_split':range(3,21,3), 'random_state': [0]}\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = GridSearchCV(clf, parameters, n_jobs = -2)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    accuracy = clf.best_score_ \n",
    "    best_params = clf.best_params_\n",
    "    best_depth = best_params['max_depth']\n",
    "    best_leaf = best_params['min_samples_leaf']\n",
    "    best_split = best_params['min_samples_split']\n",
    "\n",
    "    #using the best parameter to train the model\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=best_depth, min_samples_leaf= best_leaf, min_samples_split = best_split, random_state=0)\n",
    "    clf = clf.fit(X_train,Y_train)\n",
    "\n",
    "    #Prepare for prediction dataset\n",
    "    X_pred = result_df.loc[:,X_labels]\n",
    "\n",
    "    #make prediction for whole dataset.\n",
    "    result_df['LowPoint_Y'] = clf.predict(X_pred) == 'LowPoint_Y'        \n",
    "        \n",
    "    #delete the column 'BEERTYPE'\n",
    "    del result_df['BEERTYPE']    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#automate the process for classification \n",
    "def classify_32(self, state, isPickle):\n",
    "    \n",
    "    '''\n",
    "    This function takes in dataframe, and classify the store type to either LowPoint store or NonLowPoint store.\n",
    "        LowPoint: stores that can only sell 3.2% beer.\n",
    "        NonLowPoint: stores that can sell any beer.\n",
    "    \n",
    "    Parameter:\n",
    "    ---------\n",
    "        state: takes a string. The name of state.\n",
    "        isPickle: takes a boolean. Indicates classification method. 'True' for pickle, 'False' for grid search\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "        the dataframe with prediction result under 'LowPoint_Y' column.\n",
    "        \n",
    "    '''\n",
    "    #classification_subset \n",
    "    classification_df = self.classification_subset(self.data, state)\n",
    "    \n",
    "    #if using Pickle\n",
    "    if isPickle:\n",
    "        \n",
    "        #Decision tree model for Kansas and Minnesota\n",
    "        #If the state is Kansas:\n",
    "        if state == 'Kansas'.casefold():\n",
    "            self.decision_tree_pickle(classification_df, 'Kansas')\n",
    "\n",
    "        #If the state is Minnesota:   \n",
    "        elif state == 'Minnesota'.casefold():\n",
    "            self.decision_tree_pickle(classification_df, 'Minnesota')\n",
    "      \n",
    "    \n",
    "        #Business rule for Utah, Oklahoma, and Colorado\n",
    "        #If the state is Utah:\n",
    "        elif state == 'Utah'.casefold():\n",
    "            self.business_rule_pickle(classification_df, 'Utah')\n",
    "            \n",
    "        #If the state is Oklahoma:   \n",
    "        elif state == 'Oklahoma'.casefold():\n",
    "            self.business_rule_pickle(classification_df, 'Oklahoma')\n",
    "\n",
    "\n",
    "        #If the state is Colorado:  \n",
    "        elif state == 'Colorado'.casefold():\n",
    "            self.business_rule_pickle(classification_df, 'Colorado')\n",
    "\n",
    "        #If enter other States:\n",
    "        else:\n",
    "            print('wrong state')\n",
    "            break\n",
    "    \n",
    "    #if using grid search\n",
    "    else:\n",
    "        \n",
    "        #If the state is Kansas:\n",
    "        if state == 'Kansas'.casefold():\n",
    "            #get the query result as dataframe and get the prediction result\n",
    "            self.read_query_and_predict(classification_df, 'Kansas')\n",
    "        \n",
    "        #If the state is Minnesota:    \n",
    "        elif state == 'Minnesota'.casefold():\n",
    "            #get the query result as dataframe and get the prediction result\n",
    "            self.read_query_and_predict(classification_df, 'Minnesota')\n",
    "\n",
    "        else:\n",
    "            print('wrong state')\n",
    "            break \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cx_Oracle\n",
      "  Downloading cx_Oracle-5.3.tar.gz (129kB)\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\qguo\\AppData\\Local\\Temp\\pip-build-s_8c603c\\cx-Oracle\\setup.py\", line 174, in <module>\n",
      "        raise DistutilsSetupError(\"cannot locate an Oracle software \" \\\n",
      "    distutils.errors.DistutilsSetupError: cannot locate an Oracle software installation\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\qguo\\AppData\\Local\\Temp\\pip-build-s_8c603c\\cx-Oracle\\\n"
     ]
    }
   ],
   "source": [
    "!pip install cx_Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "\n",
    "# Specifying the ODBC driver, server name, database, etc. directly\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER=localhost;DATABASE=testdb;UID=me;PWD=pass')\n",
    "\n",
    "# Using a DSN, but providing a password as well\n",
    "cnxn = pyodbc.connect('DSN=test;PWD=password')\n",
    "\n",
    "# Create a cursor from the connection\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cx_Oracle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-214ce65a52c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcx_Oracle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcx_Oracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'amartinezcotto/Kohlia#743@tncluster6.cbi.net/EDW1TS_EX.cbi.net'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m cur.execute('''select /*+ parallel(6) */ a15.STORE_CD  RTL_STORE_CD, 'True' as \"NonLowPoint_Y\"\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mEDW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBI_CRN_F_RETAIL_DEPL_MVW_VW\u001b[0m \u001b[0ma11\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cx_Oracle'"
     ]
    }
   ],
   "source": [
    "import cx_Oracle\n",
    "con = cx_Oracle.connect('amartinezcotto/Kohlia#743@tncluster6.cbi.net/EDW1TS_EX.cbi.net')\n",
    "cur = con.cursor()\n",
    "cur.execute('''select /*+ parallel(6) */ a15.STORE_CD  RTL_STORE_CD, 'True' as \"NonLowPoint_Y\"\n",
    "from EDW.BI_CRN_F_RETAIL_DEPL_MVW_VW a11\n",
    " join EDW.BI_CRN_D_ITEM_VW a12\n",
    " on (a11.ITEM_ID = a12.ITEM_ID)\n",
    " join EDW.BI_CRN_D_REL_TIME_DETAIL_VW a13\n",
    " on (a11.DATE_ID = a13.REL_DATE_ID)\n",
    " join EDW.BI_CRN_D_DISTRIBUTOR_VW a14\n",
    " on (a11.DIST_ID = a14.DIST_ID)\n",
    " join EDW.BI_CRN_D_RETAILER_VW a15\n",
    " on (a11.RETAILER_ID = a15.RETAILER_ID)\n",
    "where (a13.REL_TIME_CD in ('L3_TY')\n",
    " and a14.STATE_PROVINCE_COUNTRY_CD in ('162')\n",
    " and a12.MASTER_SKU_CD not in ('80013450', '80013452', '80013455', '80013979', '80013456', '80013475', '80061325', '80013477', '80013982', '80013980', '80059842', '80058839', '80014020', '80014022', '80014023', '80014024', '80014025', '80013992', '80013991', '80013464', '80013466', '80013469', '80013471', '80013472', '80013473', '80013478', '80031998', '80013485', '80056926', '80058838', '80019746', '80031994', '80015966', '80014017', '80012704', '80014015', '80014009', '80014011', '80024732', '80013994', '80056172', '80014010'))\n",
    "group by a15.STORE_CD''')\n",
    "               \n",
    "row = cur.fetchone()\n",
    "       \n",
    "cur.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sql notes\n",
    "#Kansas: 162\n",
    "#Utah:239\n",
    "#Minnesota:177\n",
    "#Corolado:125\n",
    "#Oklahoma:201\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kansas decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'max_depth':range(1,21), 'min_samples_leaf':range(3,21,3), 'min_samples_split':range(3,21,3), 'random_state': [0]}\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = GridSearchCV(clf, parameters, n_jobs = -2)\n",
    "clf.fit(X, Y)\n",
    "accuracy = clf.best_score_ \n",
    "best_params = clf.best_params_\n",
    "best_depth = best_params['max_depth']\n",
    "best_leaf = best_params['min_samples_leaf']\n",
    "best_split = best_params['min_samples_split']\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=best_depth, min_samples_leaf= best_leaf, min_samples_split = best_split, random_state=0)\n",
    "clf = clf.fit(X,Y)\n",
    "# save the model to disk\n",
    "filename = 'Kansas_decision_tree_model.p'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minnesota decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'max_depth':range(1,21), 'min_samples_leaf':range(3,21,3), 'min_samples_split':range(3,21,3), 'random_state': [0]}\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = GridSearchCV(clf, parameters, n_jobs = -2)\n",
    "clf.fit(X, Y)\n",
    "accuracy = clf.best_score_ \n",
    "best_params = clf.best_params_\n",
    "best_params = clf.best_params_\n",
    "best_depth = best_params['max_depth']\n",
    "best_leaf = best_params['min_samples_leaf']\n",
    "best_split = best_params['min_samples_split']\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=best_depth, min_samples_leaf= best_leaf, min_samples_split = best_split, random_state=0)\n",
    "clf = clf.fit(X,Y)\n",
    "# save the model to Pickle\n",
    "pickle.dump(clf, open('Minnesota_decision_tree_model.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utah business rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Rules_Utah(dataframe):\n",
    "\n",
    "    for row in range(len(dataframe)):\n",
    "        if dataframe.loc[row,'RTL_CHANNEL_DSC'] == 'LIQUOR' or 'MILITARY' in dataframe.loc[row,'RTL_CHANNEL_DSC']:\n",
    "            \n",
    "            dataframe.loc[row,'LowPoint_Y'] = False\n",
    "        else:\n",
    "            \n",
    "            dataframe.loc[row,'LowPoint_Y'] = True\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "#save the Utah business rule into pickle\n",
    "pickle.dump(Rules_Utah, open('Utah_business_rule.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oklahoma business rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Rules_Oklahoma(dataframe):\n",
    "    result_list = []\n",
    "    for row in range(len(dataframe)):\n",
    "        if dataframe.loc[row,'RTL_CHANNEL_DSC'] == 'DISTRIBUTOR/SUB-DISTRIBUTOR' or dataframe.loc[row,'RTL_CHANNEL_DSC'] == 'EXTENDED MASTER OFF-PREMISE':\n",
    "                result_list.append(False)\n",
    "        else:\n",
    "                result_list.append(True)\n",
    "    return result_list\n",
    "\n",
    "#save the Oklahoma business rule into pickle\n",
    "pickle.dump(Rules_Oklahoma, open('Oklahoma_business_rule.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corolado business rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Rules_Corolado(dataframe):\n",
    "    for row in range(len(dataframe)):\n",
    "        if dataframe.loc[row,'RTL_PREMISE_TYPE_CD'] == 'OFF':\n",
    "            if dataframe.loc[row,'RTL_CHANNEL_DSC'] == 'LIQUOR' or dataframe.loc[row,'RTL_CHANNEL_DSC'] == 'DRUG' or dataframe.loc[row,'RTL_CHANNEL_DSC'] == 'MILITARY OFF-PREMISE':\n",
    "                dataframe.loc[row,'LowPoint_Y'] = False\n",
    "            elif dataframe.loc[row,'RTL_CHANNEL_DSC'] == 'GROCERY':\n",
    "                if dataframe.loc[row,'RTL_LIQUOR_FLG'] == 'Y':\n",
    "                    dataframe.loc[row,'LowPoint_Y'] = False\n",
    "                else:\n",
    "                    dataframe.loc[row,'LowPoint_Y'] = True\n",
    "            else:\n",
    "                dataframe.loc[row,'LowPoint_Y'] = True\n",
    "        else:\n",
    "             dataframe.loc[row,'LowPoint_Y'] = False\n",
    "    return dataframe\n",
    "\n",
    "#save the Corolado business rule into pickle\n",
    "pickle.dump(Rules_Corolado, open('Corolado_business_rule.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The End for the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function for production for grid search\n",
    "def decision_tree_prediction_grid(self, storeType, binary_column, delete_column):\n",
    "\n",
    "    '''\n",
    "    Use decision tree classification model with grid search to train and predict for input dataframe.\n",
    "    06/23/2017\n",
    "    \n",
    "    parameter:\n",
    "    ----------\n",
    "        \n",
    "        storeType: takes a dataframe. Data with stores and their types. (LowPoint and NonLowPoint)\n",
    "                   LowPoint: stores that can only sell 3.2% beer.\n",
    "                   NonLowPoint: stores that can sell any beer.\n",
    "        \n",
    "        binary_column: takes a string or a list of string as input. The input must be a column name present in the data. \n",
    "                       The names of columns need to be binarized.\n",
    "    \n",
    "        delete_Column: takes a string or a list of string as input. The input must be a column name present in the data. \n",
    "                       The names of the columns that don't want to be included when trainning. \n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    \n",
    "        The original dataframe with the prediction results under colomn 'PREDICTION'\n",
    "        'PREDICTION' has two values: \n",
    "                                    LowPoint: stores that can only sell 3.2% beer.\n",
    "                                    NonLowPoint: stores that can sell any beer.\n",
    "    \n",
    "    '''    \n",
    "    \n",
    "    #merge the data with their label of store type. \n",
    "    FullData = pd.merge(self.data, StoreType, on=\"RTL_STORE_CD\", how=\"left\")\n",
    "    FullData.loc[FullData['BEERTYPE'].isnull(),\"BEERTYPE\"] = \"LowPoint\"\n",
    "    \n",
    "    #call binarize function to convert columns into binary. \n",
    "    binarized_df = self.binarize(binary_column)\n",
    "    \n",
    "    #train full data with cross validation\n",
    "    #independent variables:\n",
    "    X_labels = [c for c in binarized_df.columns if c not in delete_column]\n",
    "    X = binarized_df.loc[:,X_labels]\n",
    "    Y = binarized_df['BEERTYPE']\n",
    "    \n",
    "    #train and fit the model\n",
    "    parameters = {'max_depth':range(1,21), 'min_samples_leaf':range(3,21,3), 'min_samples_split':range(3,21,3), 'random_state': [0]}\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = GridSearchCV(clf, parameters, n_jobs = -2)\n",
    "    clf.fit(X, Y)\n",
    "    accuracy = clf.best_score_ \n",
    "    best_params = clf.best_params_\n",
    "    best_depth = best_params['max_depth']\n",
    "    best_leaf = best_params['min_samples_leaf']\n",
    "    best_split = best_params['min_samples_split']\n",
    "    \n",
    "    #use the trained model to make prediction\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=best_depth, min_samples_leaf= best_leaf, min_samples_split = best_split, random_state=0)\n",
    "    clf = clf.fit(X,Y)\n",
    "    #X in fit() is wrong, need the whole data\n",
    "    self.data['LowPoint_Y'] = clf.predict(X) ==\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function for production pickle\n",
    "def decision_tree_prediction(self, delete_column):\n",
    "    '''\n",
    "    Use decision tree classification model that was saved in pickle to predict for input dataframe. This function is used after\n",
    "    function 'binarize' is processed. \n",
    "    06/23/2017\n",
    "    \n",
    "    parameter:\n",
    "    ----------\n",
    "    \n",
    "        delete_Column: takes a string or a list of string as input. The input must be a column name present in the data. \n",
    "                       The names of the columns that don't want to be included in trainning. \n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    \n",
    "        The original dataframe with the prediction results under colomn 'PREDICTION'\n",
    "        'PREDICTION' has two values: \n",
    "                                    LowPoint: stores that can only sell 3.2% beer.\n",
    "                                    NonLowPoint: stores that can sell any beer.\n",
    "    \n",
    "    '''\n",
    "    #create a result column first\n",
    "    \n",
    "    #load the model saved in pickle\n",
    "    decision_tree_model = pickle.load(open('decision_tree_model.sav', 'rb'))\n",
    "    \n",
    "    #independent variables:\n",
    "    X_labels = [c for c in self.data.columns if c not in delete_column]\n",
    "    X = self.data.loc[:,X_labels]\n",
    "    \n",
    "    #dependent variable:\n",
    "    self.data['PREDICTION'] = decision_tree_model.predict(X)\n",
    "    \n",
    "    #decision_tree_model.predict(X) == 'LowPoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
